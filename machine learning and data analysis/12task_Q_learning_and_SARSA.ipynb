{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12task_Q_learning_and_SARSA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "\n",
        "In this exercise, you will train an agent to interact and win in a not-so-friendly environment. Classically, the task is as follows: an agent and friends played frisbee (flying saucer) on the shore of a beautiful lake in early spring. As a result of an unsuccessful throw, the saucer landed on the surface of a partially frozen lake. The lake has areas with solid ice (white squares) and areas with thawed areas (black squares). The task of the agent is to go from the starting point to the point where the plate falls (finish), bypassing the thawed patches. An example of a possible lake configuration is shown in the figure.  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "rp5t9yycUsz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Four actions are available to the agent: left, up, right, and down. The game ends if the number of steps is exhausted (in our case it is 100), the agent falls under the water (black cell) or still reaches the Frisbee plate (finish). In the latter case, he receives a +1 reward, in all other cases, the reward is zero."
      ],
      "metadata": {
        "id": "LpqpvQS8UyuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simulate the interaction between the agent and the environment. For training, use the Q-learning algorithm. As a strategy, use the -greedy strategy with epsilon = 0.1. Discount factor gamma = 0.8. Set the parameter random_seed = 6."
      ],
      "metadata": {
        "id": "gRlkVUhoBxo_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "ivhekuCMUd4o"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "epsilon = 0.1 # the epsilon parameter when using the greedy strategy epsilon\n",
        "gamma = 0.8 # gamma discount factor\n",
        "random_seed = 6 # random seed\n",
        "time_delay = 1 # time delay when rendering the game process after training (seconds)\n",
        "lr_rate = 0.9 # alpha learning rate coefficient"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import the libraries, create our own 6x6 environment. S denotes the starting point. F - ice is safe, H - thaw, G - goal. The `is_slippery=False` parameter is responsible for the conditional lack of slipping. That is, if the agent has chosen the action to go to the right, then he will move to the corresponding state. In the general case, due to \"sliding\" one can end up in a different state. We also copied from the GYM library and slightly modified the ```generate_random_map ``` function to generate random maps based on ```random_seed ```."
      ],
      "metadata": {
        "id": "d9YpzoHtCnyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def generate_random_map(size, p, sd):\n",
        "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
        "    :param size: size of each side of the grid\n",
        "    :param p: probability that a tile is frozen\n",
        "    \"\"\"\n",
        "    valid = False\n",
        "    np.random.seed(sd)\n",
        "\n",
        "    # DFS to check that it's a valid path.\n",
        "    def is_valid(res):\n",
        "        frontier, discovered = [], set()\n",
        "        frontier.append((0,0))\n",
        "        while frontier:\n",
        "            r, c = frontier.pop()\n",
        "            if not (r,c) in discovered:\n",
        "                discovered.add((r,c))\n",
        "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
        "                for x, y in directions:\n",
        "                    r_new = r + x\n",
        "                    c_new = c + y\n",
        "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
        "                        continue\n",
        "                    if res[r_new][c_new] == 'G':\n",
        "                        return True\n",
        "                    if (res[r_new][c_new] not in '#H'):\n",
        "                        frontier.append((r_new, c_new))\n",
        "        return False\n",
        "\n",
        "    while not valid:\n",
        "        p = min(1, p)\n",
        "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
        "        res[0][0] = 'S'\n",
        "        res[-1][-1] = 'G'\n",
        "        valid = is_valid(res)\n",
        "    return [\"\".join(x) for x in res]\n",
        "\n",
        "# map generation\n",
        "random_map = generate_random_map(size=6, p=0.8, sd = random_seed) # create our map\n",
        "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) # environment initialization\n",
        "print(\"Map\")\n",
        "env.render() # print map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG_7fnsUCpge",
        "outputId": "208c7ca5-591e-4b38-808f-f5aeeabf651c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map\n",
            "\n",
            "\u001b[41mS\u001b[0mFHFFF\n",
            "FFFFFF\n",
            "FFFHHF\n",
            "HHFFHF\n",
            "FFFHFF\n",
            "FHFFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions for choosing an action and updating the action value table.  \n",
        "The learn() function updates the value of the current action according to the Q-learning algorithm."
      ],
      "metadata": {
        "id": "6B6OTSrHETMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_action(state):\n",
        "    action=0\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = np.random.randint(0,env.action_space.n)\n",
        "    else:\n",
        "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "def learn(state, state2, reward, action, done):\n",
        "    Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * max(Q[state2, :]) - Q[state, action])"
      ],
      "metadata": {
        "id": "3lFLwvaNETyx"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code, as a result of training the model, can indicate the number of wins and the number of the game (game) in which the agent won the fifth win in a row for the first time."
      ],
      "metadata": {
        "id": "QArjjG6nGlz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's explain what the ```env.step(action)``` function returns\n",
        "\n",
        "```state2``` -- next state\n",
        "\n",
        "```reward``` -- reward\n",
        "\n",
        "```done``` -- game end flag. True if you win or fall into a thaw. False otherwise."
      ],
      "metadata": {
        "id": "pLrfJkBEPMV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# inititalization\n",
        "np.random.seed(random_seed)\n",
        "total_games = 10000\n",
        "max_steps = 100\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "totalWins = 0\n",
        "fifthWinInRowId = -1\n",
        "winInRowCounter = 0\n",
        "inRowCountFlag = True\n",
        "\n",
        "# main cycle\n",
        "for game in tqdm(range(total_games)):\n",
        "    state = env.reset()\n",
        "    t = 0\n",
        "    while t < max_steps:\n",
        "        \n",
        "        t += 1\n",
        "\n",
        "        action = choose_action(state)\n",
        "\n",
        "        state2, reward, done, info = env.step(action)\n",
        "\n",
        "        if t == max_steps:\n",
        "            done = True  \n",
        "\n",
        "        learn(state, state2, reward, action, done)\n",
        "\n",
        "        state = state2\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    if reward == 1:\n",
        "        totalWins += 1\n",
        "        winInRowCounter += 1\n",
        "    else:\n",
        "      winInRowCounter = 0\n",
        "\n",
        "    if inRowCountFlag and (winInRowCounter == 5):\n",
        "        fifthWinInRowId = game + 1\n",
        "        inRowCountFlag = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P85pQg6TPF3O",
        "outputId": "2f8733a3-dc0e-44a5-ae15-de6e64f2f7c0"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:07<00:00, 1395.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of wins in a series of 10,000 games: \", totalWins)\n",
        "print(\"Five wins in a row for the first time in a game: \", fifthWinInRowId)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGHjxHdaSedY",
        "outputId": "18f9c832-b4df-4d5e-98d0-3c621af0c19a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of wins in a series of 10,000 games:  2202\n",
            "Five wins in a row for the first time in a game:  7473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make one game to follow the actions of the agent. In this case, we will consider the model to be fully trained, that is, the actions are chosen greedily, the values of the action values in the table are not updated."
      ],
      "metadata": {
        "id": "9s-7_KYNXwyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# greedy choice of actions\n",
        "def choose_action_one_game(state):\n",
        "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "states=[] # an array to save the states of the agent during the game\n",
        "t = 0\n",
        "state = env.reset()\n",
        "wn = 0\n",
        "while(t < 100):\n",
        "  env.render()\n",
        "  time.sleep(time_delay)\n",
        "  clear_output(wait=True)\n",
        "  action = choose_action_one_game(state)  \n",
        "  state2, reward, done, info = env.step(action)  \n",
        "  states.append(state)\n",
        "  state = state2\n",
        "  t += 1\n",
        "  if done and reward == 1:\n",
        "    wn=1\n",
        "  if done:\n",
        "    break\n",
        "if wn == 1:\n",
        "  print(\"Win\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDK9uppWXxX2",
        "outputId": "6f6dee73-8e57-498b-a596-b98aeff3a726"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's display the route"
      ],
      "metadata": {
        "id": "atE_F1sHYcPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_maze_pic(maze):\n",
        "  maze_pic=[]\n",
        "  for i in range(len(maze)):\n",
        "    row = []\n",
        "    for j in range(len(maze[i])):\n",
        "      if maze[i][j] == 'S':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'F':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'H':\n",
        "        row.append(1)\n",
        "      if maze[i][j] == 'G':\n",
        "        row.append(0)\n",
        "    maze_pic.append(row)\n",
        "  maze_pic = np.array(maze_pic)\n",
        "  return maze_pic\n",
        "  \n",
        "\n",
        "# make maze fit to plot\n",
        "maze_pic = make_maze_pic(random_map)\n",
        "nrows, ncols = maze_pic.shape\n",
        "\n",
        "# arrays of picture elements\n",
        "rw = np.remainder(states,nrows)\n",
        "cl = np.floor_divide(states,nrows)\n",
        "if wn == 1:\n",
        "  rw = np.append(rw, [nrows-1])\n",
        "  cl = np.append(cl,[ncols-1])\n",
        "\n",
        "# picture plotting\n",
        "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
        "ax1.clear()\n",
        "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
        "ax1.set_xticklabels([])\n",
        "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
        "ax1.set_yticklabels([])\n",
        "ax1.grid(True)\n",
        "ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n",
        "ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n",
        "ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n",
        "ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n",
        "ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n",
        "ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n",
        "ax1.imshow(maze_pic, cmap=\"binary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "-Oh7jjr8Yc3L",
        "outputId": "a096dd35-691b-4c5b-8135-de9fc011056b"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5cfc913bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We duplicate the resulting notebook and use the SARSA algorithm instead of the Q-learning algorithm. Please note that the task requires you to change the number of games. That is, `total_games = 40000`. Blocks should be launched sequentially from the very beginning (due to `random_seed`). Separately, we draw your attention to the fact that when changing the algorithm from Q-learning to SARSA, both the learning process and the `learn()` function are subject to modification. In addition, the `learn()` function must have an additional argument (next action)."
      ],
      "metadata": {
        "id": "8kq1ImyFYnST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map generation\n",
        "random_map = generate_random_map(size=6, p=0.8, sd = random_seed) # create our map\n",
        "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) # environment initialization\n",
        "print(\"Map\")\n",
        "env.render() # print map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsadUiuaZqAX",
        "outputId": "cd66d1df-4c6d-4c5c-e691-92e2bc83682b"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map\n",
            "\n",
            "\u001b[41mS\u001b[0mFHFFF\n",
            "FFFFFF\n",
            "FFFHHF\n",
            "HHFFHF\n",
            "FFFHFF\n",
            "FHFFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_action(state):\n",
        "    action = 0\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = np.random.randint(0,env.action_space.n)\n",
        "    else:\n",
        "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "def learn(state, state2, reward, action, action2, done):\n",
        "    Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * Q[state2, action2] - Q[state, action])"
      ],
      "metadata": {
        "id": "0X6S4EwvaZaE"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# inititalization\n",
        "np.random.seed(random_seed)\n",
        "total_games = 40000\n",
        "max_steps = 100\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "totalWins = 0\n",
        "fifthWinInRowId = -1\n",
        "winInRowCounter = 0\n",
        "inRowCountFlag = True\n",
        "\n",
        "# main cycle\n",
        "for game in tqdm(range(total_games)):\n",
        "    state = env.reset()\n",
        "    t = 0\n",
        "    action = choose_action(state)\n",
        "    while t < max_steps:\n",
        "              \n",
        "        t += 1\n",
        "\n",
        "        state2, reward, done, info = env.step(action)\n",
        "\n",
        "        action2 = choose_action(state2) # choosing an action both for the next step of the game and for updating the value of the completed action\n",
        "\n",
        "        if t == max_steps:\n",
        "          done = True  \n",
        "\n",
        "        learn(state, state2, reward, action, action2, done)\n",
        "\n",
        "        state = state2\n",
        "\n",
        "        action = action2\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    if reward == 1:\n",
        "        totalWins += 1\n",
        "        winInRowCounter += 1\n",
        "    else:\n",
        "      winInRowCounter = 0\n",
        "\n",
        "    if inRowCountFlag and (winInRowCounter == 5):\n",
        "        fifthWinInRowId = game + 1\n",
        "        inRowCountFlag = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBV1OQiLZBXm",
        "outputId": "e2b2dc25-3b4c-4409-efb1-c3bbbd98ce9a"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40000/40000 [00:39<00:00, 1018.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of wins in a series of 40,000 games: \", totalWins)\n",
        "print(\"Five wins in a row for the first time in a game: \", fifthWinInRowId)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pj7BQZ7alYe",
        "outputId": "9d149332-a2b4-4ad3-a75a-3090d1235d39"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of wins in a series of 40,000 games:  29241\n",
            "Five wins in a row for the first time in a game:  1399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# greedy choice of actions\n",
        "def choose_action_one_game(state):\n",
        "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "states=[] # an array to save the states of the agent during the game\n",
        "t = 0\n",
        "state = env.reset()\n",
        "wn = 0\n",
        "while(t < 100):\n",
        "  env.render()\n",
        "  time.sleep(time_delay)\n",
        "  clear_output(wait=True)\n",
        "  action = choose_action_one_game(state)  \n",
        "  state2, reward, done, info = env.step(action)  \n",
        "  states.append(state)\n",
        "  state = state2\n",
        "  t += 1\n",
        "  if done and reward == 1:\n",
        "    wn=1\n",
        "  if done:\n",
        "    break\n",
        "if wn == 1:\n",
        "  print(\"Win\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YScNok9Uj92Z",
        "outputId": "56a0ada0-1aa0-4b93-b131-29034e9a4164"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Win\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_maze_pic(maze):\n",
        "  maze_pic=[]\n",
        "  for i in range(len(maze)):\n",
        "    row = []\n",
        "    for j in range(len(maze[i])):\n",
        "      if maze[i][j] == 'S':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'F':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'H':\n",
        "        row.append(1)\n",
        "      if maze[i][j] == 'G':\n",
        "        row.append(0)\n",
        "    maze_pic.append(row)\n",
        "  maze_pic = np.array(maze_pic)\n",
        "  return maze_pic\n",
        "  \n",
        "\n",
        "# make maze fit to plot\n",
        "maze_pic = make_maze_pic(random_map)\n",
        "nrows, ncols = maze_pic.shape\n",
        "\n",
        "# arrays of picture elements\n",
        "rw = np.remainder(states,nrows)\n",
        "cl = np.floor_divide(states,nrows)\n",
        "if wn == 1:\n",
        "  rw = np.append(rw, [nrows-1])\n",
        "  cl = np.append(cl,[ncols-1])\n",
        "\n",
        "# picture plotting\n",
        "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
        "ax1.clear()\n",
        "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
        "ax1.set_xticklabels([])\n",
        "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
        "ax1.set_yticklabels([])\n",
        "ax1.grid(True)\n",
        "ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n",
        "ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n",
        "ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n",
        "ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n",
        "ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n",
        "ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n",
        "ax1.imshow(maze_pic, cmap=\"binary\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "0gfVHWSRkNgC",
        "outputId": "894ebece-0d4f-43a2-8c08-8135591ca5c0"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5cfc8fb390>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}